name: null
model:
  sample_rate: 16000
  label_smoothing: 0.0
  use_loss_mask_for_prompt: false
  log_prediction: true
  prompt_format: canary2
  prompt_defaults:
  - role: user
    slots:
      decodercontext: ''
      source_lang: <|en|>
      target_lang: <|en|>
      emotion: <|emo:undefined|>
      pnc: <|pnc|>
      itn: <|noitn|>
      diarize: <|nodiarize|>
      timestamp: <|notimestamp|>
  multitask_metrics_cfg:
    log_predictions: true
    metrics:
      wer:
        _target_: nemo.collections.asr.metrics.WER
        constraint: .source_lang==.target_lang
      bleu:
        _target_: nemo.collections.asr.metrics.BLEU
        constraint: .source_lang!=.target_lang
        bleu_tokenizer: 13a
        check_cuts_for_bleu_tokenizers: false
  model_defaults:
    asr_enc_hidden: 1024
    lm_enc_hidden: 512
    lm_dec_hidden: 1024
  train_ds:
    use_lhotse: true
    tarred_audio_filepaths: null
    manifest_filepath: ???
    sample_rate: ${model.sample_rate}
    shuffle: true
    num_workers: 8
    batch_size: null
    batch_duration: 360
    quadratic_duration: 15
    use_bucketing: true
    num_buckets: 20
    bucket_buffer_size: 20000
    shuffle_buffer_size: 10000
    text_field: text
    lang_field: target_lang
  validation_ds:
    use_lhotse: true
    manifest_filepath: ???
    sample_rate: ${model.sample_rate}
    batch_size: 8
    shuffle: false
    num_workers: 4
    pin_memory: true
    use_start_end_token: true
    use_bucketing: false
    text_field: text
    lang_field: target_lang
  test_ds:
    use_lhotse: true
    manifest_filepath: ???
    sample_rate: ${model.sample_rate}
    batch_size: 8
    shuffle: false
    num_workers: 4
    pin_memory: true
    use_start_end_token: true
    use_bucketing: false
  tokenizer:
    dir: null
    type: agg
    langs:
      spl_tokens:
        dir: ./tokenizers/spl_tokens
        type: bpe
      en:
        dir: ./tokenizers
        type: bpe
    custom_tokenizer:
      _target_: nemo.collections.common.tokenizers.canary_tokenizer.CanaryTokenizer
      tokenizers: null
  preprocessor:
    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor
    sample_rate: ${model.sample_rate}
    normalize: per_feature
    window_size: 0.025
    window_stride: 0.01
    window: hann
    features: 128
    n_fft: 512
    log: true
    frame_splicing: 1
    dither: 1.0e-05
    pad_to: 0
    pad_value: 0.0
  spec_augment:
    _target_: nemo.collections.asr.modules.SpectrogramAugmentation
    freq_masks: 2
    time_masks: 10
    freq_width: 27
    time_width: 0.05
  encoder:
    _target_: nemo.collections.asr.modules.ConformerEncoder
    feat_in: ${model.preprocessor.features}
    feat_out: -1
    n_layers: 24
    d_model: ${model.model_defaults.asr_enc_hidden}
    subsampling: dw_striding
    subsampling_factor: 8
    subsampling_conv_channels: 256
    causal_downsampling: false
    reduction: null
    reduction_position: null
    reduction_factor: 1
    ff_expansion_factor: 4
    self_attention_model: rel_pos
    n_heads: 8
    att_context_size:
    - -1
    - -1
    xscaling: false
    untie_biases: true
    pos_emb_max_len: 5000
    conv_kernel_size: 9
    conv_norm_type: batch_norm
    conv_context_size: null
    dropout: 0.1
    dropout_pre_encoder: 0.1
    dropout_emb: 0.0
    dropout_att: 0.1
  transf_encoder:
    _target_: nemo.collections.asr.modules.transformer.transformer_encoders.TransformerEncoder
    num_layers: 0
    hidden_size: ${model.model_defaults.lm_enc_hidden}
    inner_size: ${multiply:${model.model_defaults.lm_enc_hidden}, 4}
    num_attention_heads: 8
    ffn_dropout: 0.1
    attn_score_dropout: 0.1
    attn_layer_dropout: 0.1
    mask_future: false
    pre_ln: true
    pre_ln_final_layer_norm: true
  transf_decoder:
    _target_: nemo.collections.asr.modules.transformer.get_nemo_transformer
    model_name: null
    pretrained: false
    encoder: null
    pre_ln_final_layer_norm: true
    config_dict:
      max_sequence_length: 512
      num_token_types: 0
      embedding_dropout: 0.1
      learn_positional_encodings: false
      hidden_size: ${model.model_defaults.lm_dec_hidden}
      inner_size: ${multiply:${model.model_defaults.lm_dec_hidden}, 4}
      num_layers: 24
      num_attention_heads: 8
      ffn_dropout: 0.1
      attn_score_dropout: 0.1
      attn_layer_dropout: 0.1
      hidden_act: relu
      pre_ln: true
      vocab_size: None
  head:
    _target_: nemo.collections.asr.parts.submodules.token_classifier.TokenClassifier
    num_layers: 1
    activation: relu
    log_softmax: true
    hidden_size: ${model.transf_decoder.config_dict.hidden_size}
    num_classes: None
    dropout: 0.0
    use_transformer_init: true
  decoding:
    strategy: beam
    return_best_hypothesis: true
    beam:
      beam_size: 1
      len_pen: 0.0
      max_generation_delta: 50
  loss:
    _target_: nemo.collections.common.losses.smoothed_cross_entropy.SmoothedCrossEntropyLoss
    label_smoothing: ${model.label_smoothing}
    pad_id: null
  optim:
    name: adamw
    lr: 0.0003
    betas:
    - 0.9
    - 0.98
    weight_decay: 0.001
    sched:
      name: InverseSquareRootAnnealing
      warmup_steps: 2500
      warmup_ratio: null
      min_lr: 1.0e-06
trainer:
  devices: -1
  num_nodes: 1
  max_epochs: -1
  max_steps: 100000
  val_check_interval: 1.0
  accelerator: auto
  strategy:
    _target_: lightning.pytorch.strategies.DDPStrategy
    gradient_as_bucket_view: true
  accumulate_grad_batches: 1
  gradient_clip_val: 0.0
  precision: bf16-mixed
  log_every_n_steps: 100
  enable_progress_bar: true
  num_sanity_val_steps: 2
  check_val_every_n_epoch: 1
  sync_batchnorm: true
  enable_checkpointing: false
  logger: false
  use_distributed_sampler: false
exp_manager:
  exp_dir: null
  name: ${name}
  create_tensorboard_logger: true
  create_checkpoint_callback: true
  checkpoint_callback_params:
    monitor: val_loss
    mode: min
    save_top_k: 3
    always_save_nemo: true
  resume_from_checkpoint: null
  resume_if_exists: true
  resume_ignore_no_checkpoint: false
  create_wandb_logger: false
  wandb_logger_kwargs:
    name: null
    project: null
init_from_pretrained_model: nvidia/canary-1b-v2
